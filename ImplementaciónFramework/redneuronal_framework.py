# -*- coding: utf-8 -*-
"""RedNeuronal_Framework.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zdSPT0jEyOt3PbswoxYRlC8HhY05FD5x
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# ---------------DIVISIÓN DEL DATASET---------------
df = pd.read_excel('Obesidad_red.xlsx') # Cargar el dataset
df['Obesidad'] = df['Obesidad'].map({'si': 1, 'no': 0}) # Convertir la columna "Obesidad" (etiquetas) a valores binarios

X = df[['Peso (kg)', 'Altura (m)']].values # Extraer características (peso y altura)
y = df['Obesidad'].values # Extraer etiquetas (obesidad)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # Dividir en conjuntos de entrenamiento (70%) y prueba (30%)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42) # Dividir conjunto de entrenamiento en entrenamiento (80%) y validación (20%)

# ---------------CONSTRUCCIÓN DE LA RED NEURONAL---------------
model = Sequential()  # Crear un modelo secuencial

# Añadir una capa oculta con 4 neuronas y una función de activación 'relu'
model.add(Dense(units=4, activation='relu', input_shape=(X_train.shape[1],))) # La entrada es el número de características (peso y altura)
model.add(Dense(units=1, activation='sigmoid')) # Añadir la capa de salida con 1 neurona y función de activación 'sigmoid' para la clasificación binaria
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # Compilar el modelo usando el optimizador 'adam', la función de pérdida 'binary_crossentropy', y medir la precisión

# ---------------ENTRENAMIENTO---------------
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), batch_size=10) # Entrenar el modelo con los datos de entrenamiento y validación durante 100 épocas, con un batch size de 10

plt.figure(figsize=(12, 4)) # Visualizar la evolución del entrenamiento

plt.subplot(1, 2, 1) # Graficar la pérdida a lo largo de las épocas
plt.plot(history.history['loss'], label='Entrenamiento') # Pérdida en el conjunto de entrenamiento
plt.plot(history.history['val_loss'], label='Validación') # Pérdida en el conjunto de validación
plt.title('Pérdida durante el entrenamiento y la validación')
plt.xlabel('Época')
plt.ylabel('Pérdida')
plt.legend()

# Graficar la precisión a lo largo de las épocas
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Entrenamiento')  # Precisión en el conjunto de entrenamiento
plt.plot(history.history['val_accuracy'], label='Validación')  # Precisión en el conjunto de validación
plt.title('Precisión durante el entrenamiento y la validación')
plt.xlabel('Época')  # Etiqueta del eje X
plt.ylabel('Precisión')  # Etiqueta del eje Y
plt.legend()
plt.show()

# ---------------EVALUACIÓN---------------
test_loss, test_accuracy = model.evaluate(X_test, y_test) # Evaluar la pérdida y la precisión en el conjunto de prueba

# ---------------PREDICCIÓN---------------
test_predictions = (model.predict(X_test) > 0.5).astype(int) # Aplicar un umbral de 0.5 para convertir las probabilidades en etiquetas binarias (1 o 0)

# ---------------MATRIZ DE CONFUSIÓN---------------
def plot_confusion(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred) # Calcular la matriz de confusión
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap=plt.cm.Blues)  # Graficar la matriz con un mapa de colores
    plt.title(title)
    plt.show()

plot_confusion(y_test, test_predictions, "Matriz de confusión - Prueba")  # Mostrar la matriz de confusión para el conjunto de prueba

# ---------------EVALUACIÓN DE PRUEBA---------------
print("\nMétricas de prueba:")
print(f"Accuracy: {accuracy_score(y_test, test_predictions)}") # Calcular y mostrar la precisión
print(f"Recall: {recall_score(y_test, test_predictions)}") # Calcular y mostrar el recall (sensibilidad)
print(f"F1 Score: {f1_score(y_test, test_predictions)}\n") # Calcular y mostrar el F1 Score