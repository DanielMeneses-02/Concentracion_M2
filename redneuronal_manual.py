# -*- coding: utf-8 -*-
"""RedNeuronal_Manual.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WyxLGzLHPYywli2eOBHCVaW2ZoF9IHRE
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score, ConfusionMatrixDisplay

# ---------------DIVISIÓN DEL DATASET---------------
df = pd.read_excel('datos_obesidad.xlsx') # Cargar el dataset
df['Obesidad'] = df['Obesidad'].map({'si': 1, 'no': 0}) # Convertir la columna "Obesidad" (etiquetas) a valores binarios

X = df[['Peso (kg)', 'Altura (m)']].values # Extraer características (peso y altura)
y = df['Obesidad'].values # Extraer etiquetas (obesidad)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # Dividir en conjuntos de entrenamiento (70%) y prueba (30%)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42) # Dividir conjunto de entrenamiento en entrenamiento (80%) y validación (20%)

# ---------------PREPARACIÓN DE DATOS---------------
X_train = X_train.T # Transponer las matrices de características para que cada columna sea un ejemplo
X_val = X_val.T
X_test = X_test.T

y_train = y_train.reshape(1, -1) # Redimensionar las etiquetas para que sean compatibles con la salida de la red neuronal
y_val = y_val.reshape(1, -1)
y_test = y_test.reshape(1, -1)

# ---------------PARAMETROS INICIALES---------------
def initialize_parameters(n_x, n_h, n_y): # Función para incializar los parametros
    np.random.seed(42)  # Fijar la semilla para reproducibilidad
    w1 = np.random.randn(n_h, n_x) * 0.01  # Inicializar pesos de la capa oculta
    b1 = np.zeros((n_h, 1))  # Inicializar sesgos de la capa oculta
    w2 = np.random.randn(n_y, n_h) * 0.01  # Inicializar pesos de la capa de salida
    b2 = np.zeros((n_y, 1))  # Inicializar sesgos de la capa de salida

    parameters = {"w1": w1, "b1": b1, "w2": w2, "b2": b2} # Guardar gradientes en 'parameters'
    return parameters

# ---------------FUNCIÓN DE ACTIVACIÓN---------------
def sigmoid(Z):
    return 1 / (1 + np.exp(-Z)) # Función de activación sigmoide

def sigmoid_derivative(Z):
    return Z * (1 - Z) # Derivada de la función sigmoide para el cálculo del gradiente

# ---------------FEED FORWARD---------------
def forward_propagation(X, parameters):
    w1 = parameters['w1'] # Extraer parámetros
    b1 = parameters['b1']
    w2 = parameters['w2']
    b2 = parameters['b2']

    C1 = np.dot(w1, X) + b1 # Calcular el valor de entrada a la capa oculta
    A1 = sigmoid(C1) # Activación sigmoidal

    C2 = np.dot(w2, A1) + b2 # Calcular el valor de entrada a la capa oculta
    A2 = sigmoid(C2) # Activación sigmoidal

    cache = {"C1": C1, "A1": A1, "C2": C2, "A2": A2} # Guardar valores intermedios en 'cache' para su uso en Backpropagation
    return A2, cache

# ---------------BACKPROPAGATION---------------
def backward_propagation(parameters, cache, X, Y):
    m = X.shape[1]  # Número de ejemplos de entrenamiento

    w2 = parameters['w2'] # Extraer parámetros intermedios
    A1 = cache['A1'] # Extraer activaciones intermedias
    A2 = cache['A2']

    dC2 = A2 - Y # Calcular el error de la capa de salida
    dw2 = (1 / m) * np.dot(dC2, A1.T) # Calcular el gradiente de los pesos de la capa de salida
    db2 = (1 / m) * np.sum(dC2, axis=1, keepdims=True) # Calcular el gradiente de los sesgos de la capa de salida

    dA1 = np.dot(w2.T, dC2) # Propagar el error hacia atrás desde la capa de salida a la capa oculta
    dC1 = dA1 * sigmoid_derivative(A1) # Calcular el gradiente de la capa oculta mediante la derivada de la función sigmoide
    dw1 = (1 / m) * np.dot(dC1, X.T) # Calcular el gradiente de los pesos de la capa oculta
    db1 = (1 / m) * np.sum(dC1, axis=1, keepdims=True) # Calcular el gradiente de los sesgos de la capa oculta

    grads = {"dw1": dw1, "db1": db1, "dw2": dw2, "db2": db2} # Guardar gradientes en 'grads'
    return grads

# ---------------ACTUALIZACIÓN---------------
def update_parameters(parameters, grads, learning_rate):
    w1 = parameters['w1'] - learning_rate * grads['dw1'] # Actualizar los parámetros usando el gradiente descendente
    b1 = parameters['b1'] - learning_rate * grads['db1']
    w2 = parameters['w2'] - learning_rate * grads['dw2']
    b2 = parameters['b2'] - learning_rate * grads['db2']

    parameters = {"w1": w1, "b1": b1, "w2": w2, "b2": b2}
    return parameters

# ---------------ENTRENAMIENTO---------------
def train(X, Y, n_h, num_iterations=10000, learning_rate=0.01):
    n_x = X.shape[0]  # Número de características de entrada
    n_y = Y.shape[0]  # Número de clases (salida)

    parameters = initialize_parameters(n_x, n_h, n_y) # Inicializar los parámetros

    for i in range(num_iterations): # Iterar para entrenar la red
        A2, cache = forward_propagation(X, parameters) # Propagar hacia adelante para obtener la salida 'A2'
        grads = backward_propagation(parameters, cache, X, Y) # Realizar backpropagation para calcular los gradientes
        parameters = update_parameters(parameters, grads, learning_rate) # Actualizar los parámetros

        if i % 1000 == 0: # Imprimir el costo cada 1000 iteraciones
            cost = np.mean((Y - A2) ** 2) # Calcular el error cuadrático medio
            print(f"Costo en iteración {i}: {cost}")

    # Imprimir el costo final y los pesos finales
    final_cost = np.mean((Y - A2) ** 2) # Calcular el error cuadrático medio final
    print("\n------COSTO FINAL------")
    print(f"- Costo final después de {num_iterations} iteraciones: {final_cost}\n")

    print("\n------PESOS FINALES------")
    print(f"- w1: {parameters['w1']}\n")
    print(f"- b1: {parameters['b1']}\n")
    print(f"- w2: {parameters['w2']}\n")
    print(f"- b2: {parameters['b2']}\n")

    return parameters

# ---------------PREDICCIÓN---------------
def predict(X, parameters):
    A2, _ = forward_propagation(X, parameters) # Realizar la propagación hacia adelante para obtener las predicciones
    predictions = (A2 > 0.5).astype(int)  # Aplicar umbral para clasificación binaria
    return predictions

# ---------------EVALUACIÓN DE ENTRENAMIENTO---------------
parameters = train(X_train, y_train, n_h=4, num_iterations=100000, learning_rate=0.001) # Entrenar la red neuronal con 4 neuronas en la capa oculta, 100000 iteraciones y tasa de aprendizaje de 0.001

train_predictions = predict(X_train, parameters) # Evaluar en los conjuntos de entrenamiento y validación
val_predictions = predict(X_val, parameters)

# ---------------MATRIZ DE CONFUSIÓN---------------
def plot_confusion(y_true, y_pred, title):
    cm = confusion_matrix(y_true.flatten(), y_pred.flatten())
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(cmap=plt.cm.Blues)
    plt.title(title)
    plt.show()

plot_confusion(y_train, train_predictions, "\nMatriz de confusión - Entrenamiento") # Imprimir matriz de confusión para el conjunto de entrenamiento
print("Métricas de entrenamiento:") # Imprimir métricas para el conjunto de entrenamiento
print(f"Accuracy: {accuracy_score(y_train.flatten(), train_predictions.flatten())}")
print(f"Recall: {recall_score(y_train.flatten(), train_predictions.flatten())}")
print(f"F1 Score: {f1_score(y_train.flatten(), train_predictions.flatten())}\n")

plot_confusion(y_val, val_predictions, "\nMatriz de confusión - Validación") # Imprimir matriz de confusión para el conjunto de validación
print("Métricas de validación:") # Imprimir métricas para el conjunto de validación
print(f"Accuracy: {accuracy_score(y_val.flatten(), val_predictions.flatten())}")
print(f"Recall: {recall_score(y_val.flatten(), val_predictions.flatten())}")
print(f"F1 Score: {f1_score(y_val.flatten(), val_predictions.flatten())}\n")

# ---------------EVALUACIÓN DE PRUEBA---------------
test_predictions = predict(X_test, parameters) # Realizar predicciones en el conjunto de prueba

plot_confusion(y_test, test_predictions, "\nMatriz de confusión - Prueba") # Imprimir matriz de confusión para el conjunto de prueba
print("Métricas de prueba:") # Imprimir métricas para el conjunto de prueba
print(f"Accuracy: {accuracy_score(y_test.flatten(), test_predictions.flatten())}")
print(f"Recall: {recall_score(y_test.flatten(), test_predictions.flatten())}")
print(f"F1 Score: {f1_score(y_test.flatten(), test_predictions.flatten())}\n")